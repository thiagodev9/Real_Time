A arquitetura de ETL em tempo real, integrando diversas ferramentas.
O Apache Airflow será usado para orquestração de workflows, enquanto o Kafka será usado para gerenciaro streaming de dados em tempo real.
O PySpark será utilizado para processamento distribuído de dadose o resultado do processamento em tempo real será armazenado em um banco de dados NoSQL.
Todo o pipeline será criado para funcionar de forma automatizada.
